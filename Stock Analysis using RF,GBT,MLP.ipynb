{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "876f08e4-2356-4830-906b-ceba04254847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, avg, when\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "spark = SparkSession.builder.appName(\"StockSentimentAnalysis\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41aae9ef-d7d6-4c97-88f7-698c1ad20121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentiment data\n",
    "sentiment_df = spark.read.csv(\"classified_news_sentiment.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Convert date to standard format\n",
    "sentiment_df = sentiment_df.withColumn(\"Date\", to_date(col(\"Date\"), \"dd-MM-yyyy\"))\n",
    "\n",
    "# Load stock data for AAPL as an example\n",
    "aapl_df = spark.read.csv(\"stockdata/AAPL.csv\", header=True, inferSchema=True)\n",
    "aapl_df = aapl_df.withColumn(\"date\", to_date(col(\"date\"), \"dd-MM-yyyy\"))\n",
    "\n",
    "acn_df = spark.read.csv(\"stockdata/ACN.csv\", header=True, inferSchema=True)\n",
    "acn_df = acn_df.withColumn(\"date\", to_date(col(\"date\"), \"dd-MM-yyyy\"))\n",
    "\n",
    "amd_df = spark.read.csv(\"stockdata/AMD.csv\", header=True, inferSchema=True)\n",
    "amd_df = amd_df.withColumn(\"date\", to_date(col(\"date\"), \"dd-MM-yyyy\"))\n",
    "\n",
    "amzn_df = spark.read.csv(\"stockdata/AMZN.csv\", header=True, inferSchema=True)\n",
    "amzn_df = amzn_df.withColumn(\"date\", to_date(col(\"date\"), \"dd-MM-yyyy\"))\n",
    "\n",
    "googl_df = spark.read.csv(\"stockdata/GOOGL.csv\", header=True, inferSchema=True)\n",
    "googl_df = googl_df.withColumn(\"date\", to_date(col(\"date\"), \"dd-MM-yyyy\"))\n",
    "\n",
    "ibm_df = spark.read.csv(\"stockdata/IBM.csv\", header=True, inferSchema=True)\n",
    "ibm_df = ibm_df.withColumn(\"date\", to_date(col(\"date\"), \"dd-MM-yyyy\"))\n",
    "\n",
    "infy_df = spark.read.csv(\"stockdata/INFY.csv\", header=True, inferSchema=True)\n",
    "infy_df = infy_df.withColumn(\"date\", to_date(col(\"date\"), \"dd-MM-yyyy\"))\n",
    "\n",
    "msft_df = spark.read.csv(\"stockdata/MSFT.csv\", header=True, inferSchema=True)\n",
    "msft_df = msft_df.withColumn(\"date\", to_date(col(\"date\"), \"dd-MM-yyyy\"))\n",
    "\n",
    "orcl_df = spark.read.csv(\"stockdata/ORCL.csv\", header=True, inferSchema=True)\n",
    "orcl_df = orcl_df.withColumn(\"date\", to_date(col(\"date\"), \"dd-MM-yyyy\"))\n",
    "\n",
    "sap_df = spark.read.csv(\"stockdata/SAP.csv\", header=True, inferSchema=True)\n",
    "sap_df = sap_df.withColumn(\"date\", to_date(col(\"date\"), \"dd-MM-yyyy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8e3fef-d98e-4b84-b016-bfff58f0f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join sentiment and stock price data on ticker and date\n",
    "joined_df = sentiment_df.join(aapl_df, (sentiment_df.Ticker == 'AAPL') & (sentiment_df.Date == aapl_df.date), \"inner\")\n",
    "joined_df = sentiment_df.join(acn_df, (sentiment_df.Ticker == 'ACN') & (sentiment_df.Date == acn_df.date), \"inner\")\n",
    "joined_df = sentiment_df.join(amd_df, (sentiment_df.Ticker == 'AMD') & (sentiment_df.Date == amd_df.date), \"inner\")\n",
    "joined_df = sentiment_df.join(amzn_df, (sentiment_df.Ticker == 'AMZN') & (sentiment_df.Date == amzn_df.date), \"inner\")\n",
    "joined_df = sentiment_df.join(googl_df, (sentiment_df.Ticker == 'GOOGL') & (sentiment_df.Date == googl_df.date), \"inner\")\n",
    "joined_df = sentiment_df.join(ibm_df, (sentiment_df.Ticker == 'IBM') & (sentiment_df.Date == ibm_df.date), \"inner\")\n",
    "joined_df = sentiment_df.join(infy_df, (sentiment_df.Ticker == 'INFY') & (sentiment_df.Date == infy_df.date), \"inner\")\n",
    "joined_df = sentiment_df.join(msft_df, (sentiment_df.Ticker == 'MSFT') & (sentiment_df.Date == msft_df.date), \"inner\")\n",
    "joined_df = sentiment_df.join(orcl_df, (sentiment_df.Ticker == 'ORCL') & (sentiment_df.Date == orcl_df.date), \"inner\")\n",
    "joined_df = sentiment_df.join(sap_df, (sentiment_df.Ticker == 'SAP') & (sentiment_df.Date == sap_df.date), \"inner\")\n",
    "\n",
    "\n",
    "# Create a new column: price movement (Up/Down)\n",
    "joined_df = joined_df.withColumn(\n",
    "    \"Price_Change\",\n",
    "    when(col(\"close\") > col(\"open\"), 1).otherwise(0)  # 1 for Up, 0 for Down\n",
    ")\n",
    "\n",
    "# Encode sentiment\n",
    "sentiment_indexer = StringIndexer(inputCol=\"Sentiment\", outputCol=\"Sentiment_Index\")\n",
    "joined_df = sentiment_indexer.fit(joined_df).transform(joined_df)\n",
    "\n",
    "# Feature assembly\n",
    "feature_cols = [\"Sentiment_Score\", \"Sentiment_Index\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "assembled_df = assembler.transform(joined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6781309b-651d-4e6c-a8ea-52454b37ab8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|Price_Change|avg(Sentiment_Score)|\n",
      "+------------+--------------------+\n",
      "|           1| 0.12051860465116278|\n",
      "|           0| 0.20363714285714282|\n",
      "+------------+--------------------+\n",
      "\n",
      "+---------+-----+\n",
      "|Sentiment|count|\n",
      "+---------+-----+\n",
      "|  Neutral|  306|\n",
      "| Positive|  358|\n",
      "| Negative|  168|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average sentiment score by price movement\n",
    "joined_df.groupBy(\"Price_Change\").agg(avg(\"Sentiment_Score\")).show()\n",
    "\n",
    "# Count of sentiments\n",
    "sentiment_df.groupBy(\"Sentiment\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "806bece9-62fb-4119-87f3-9790b0162f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = assembled_df.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6610a991-d5e0-43a4-88a2-8c596a28f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "rf = RandomForestClassifier(labelCol=\"Price_Change\", featuresCol=\"features\", numTrees=50)\n",
    "model = rf.fit(train_df)\n",
    "\n",
    "# Predictions\n",
    "predictions = model.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc50ff8a-7796-452e-9b9a-c11891733180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Performance:\n",
      " - Accuracy : 0.76\n",
      " - Precision: 0.83\n",
      " - Recall   : 0.76\n",
      " - F1-Score : 0.72\n",
      " - AUC (ROC): 0.53\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# Accuracy\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Price_Change\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "\n",
    "# Precision (weighted)\n",
    "evaluator_precision = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Price_Change\", predictionCol=\"prediction\", metricName=\"weightedPrecision\"\n",
    ")\n",
    "precision = evaluator_precision.evaluate(predictions)\n",
    "\n",
    "# Recall (weighted)\n",
    "evaluator_recall = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Price_Change\", predictionCol=\"prediction\", metricName=\"weightedRecall\"\n",
    ")\n",
    "recall = evaluator_recall.evaluate(predictions)\n",
    "\n",
    "# F1-Score (weighted)\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Price_Change\", predictionCol=\"prediction\", metricName=\"f1\"\n",
    ")\n",
    "f1 = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "# AUC (using BinaryClassificationEvaluator, applicable for multiclass with 1-vs-rest strategy)\n",
    "evaluator_auc = BinaryClassificationEvaluator(\n",
    "    labelCol=\"Price_Change\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\"\n",
    ")\n",
    "auc = evaluator_auc.evaluate(predictions)\n",
    "\n",
    "# Print all metrics\n",
    "print(f\"Random Forest Classifier Performance:\")\n",
    "print(f\" - Accuracy : {accuracy:.2f}\")\n",
    "print(f\" - Precision: {precision:.2f}\")\n",
    "print(f\" - Recall   : {recall:.2f}\")\n",
    "print(f\" - F1-Score : {f1:.2f}\")\n",
    "print(f\" - AUC (ROC): {auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9750b81-b710-4ac5-ae5b-c1581e872ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|Price_Change|prediction|\n",
      "+------------+----------+\n",
      "|           0|       1.0|\n",
      "|           0|       1.0|\n",
      "|           1|       1.0|\n",
      "|           1|       1.0|\n",
      "|           1|       1.0|\n",
      "+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "# Initialize GBTClassifier\n",
    "gbt = GBTClassifier(\n",
    "    labelCol=\"Price_Change\",\n",
    "    featuresCol=\"features\",\n",
    "    maxIter=50,\n",
    "    maxDepth=5\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "gbt_model = gbt.fit(train_df)\n",
    "\n",
    "# Predict\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_predictions.select(\"Price_Change\", \"prediction\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96d79437-8789-4f9e-a7e3-f16aa14e7f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT Classifier Performance:\n",
      " - Accuracy : 0.76\n",
      " - Precision: 0.83\n",
      " - Recall   : 0.76\n",
      " - F1-Score : 0.72\n",
      " - AUC (Area Under ROC): 0.53\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Accuracy\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Price_Change\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "accuracy = evaluator_accuracy.evaluate(gbt_predictions)\n",
    "\n",
    "# Precision\n",
    "evaluator_precision = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Price_Change\", predictionCol=\"prediction\", metricName=\"weightedPrecision\"\n",
    ")\n",
    "precision = evaluator_precision.evaluate(gbt_predictions)\n",
    "\n",
    "# Recall\n",
    "evaluator_recall = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Price_Change\", predictionCol=\"prediction\", metricName=\"weightedRecall\"\n",
    ")\n",
    "recall = evaluator_recall.evaluate(gbt_predictions)\n",
    "\n",
    "# F1-score\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Price_Change\", predictionCol=\"prediction\", metricName=\"f1\"\n",
    ")\n",
    "f1 = evaluator_f1.evaluate(gbt_predictions)\n",
    "\n",
    "# Print all metrics\n",
    "print(f\"GBT Classifier Performance:\")\n",
    "print(f\" - Accuracy : {accuracy:.2f}\")\n",
    "print(f\" - Precision: {precision:.2f}\")\n",
    "print(f\" - Recall   : {recall:.2f}\")\n",
    "print(f\" - F1-Score : {f1:.2f}\")\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# AUC\n",
    "evaluator_auc = BinaryClassificationEvaluator(\n",
    "    labelCol=\"Price_Change\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\"\n",
    ")\n",
    "auc = evaluator_auc.evaluate(gbt_predictions)\n",
    "\n",
    "# Display result\n",
    "print(f\" - AUC (Area Under ROC): {auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c30c7a21-a94a-4631-a7a4-cb8c7e19718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|Price_Change|prediction|\n",
      "+------------+----------+\n",
      "|           0|       1.0|\n",
      "|           0|       0.0|\n",
      "|           1|       1.0|\n",
      "|           1|       1.0|\n",
      "|           1|       1.0|\n",
      "+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "# Assuming your features vector size is `input_size`\n",
    "input_size = len(train_df.select(\"features\").first()[0])  # dynamically get input size\n",
    "\n",
    "mlp = MultilayerPerceptronClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"Price_Change\",\n",
    "    predictionCol=\"prediction\",\n",
    "    layers=[input_size, 10, 5, 2],  # [input, hidden1, hidden2, output]\n",
    "    blockSize=128,\n",
    "    maxIter=100\n",
    ")\n",
    "\n",
    "mlp_model = mlp.fit(train_df)\n",
    "mlp_predictions = mlp_model.transform(test_df)\n",
    "mlp_predictions.select(\"Price_Change\", \"prediction\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "205c9ef7-2f3c-421e-bc4c-02f6444af139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron Classifier:\n",
      "  Accuracy : 0.8235\n",
      "  F1 Score : 0.8047\n",
      "  Precision: 0.8613\n",
      "  Recall   : 0.8235\n",
      "  AUC (ROC) for Multi Layer Perceptron: 0.3182\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# Multiclass Evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Price_Change\", predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# Accuracy\n",
    "accuracy = evaluator.setMetricName(\"accuracy\").evaluate(mlp_predictions)\n",
    "\n",
    "# F1 Score\n",
    "f1 = evaluator.setMetricName(\"f1\").evaluate(mlp_predictions)\n",
    "\n",
    "# Precision\n",
    "precision = evaluator.setMetricName(\"weightedPrecision\").evaluate(mlp_predictions)\n",
    "\n",
    "# Recall\n",
    "recall = evaluator.setMetricName(\"weightedRecall\").evaluate(mlp_predictions)\n",
    "\n",
    "print(f\"Multilayer Perceptron Classifier:\")\n",
    "print(f\"  Accuracy : {accuracy:.4f}\")\n",
    "print(f\"  F1 Score : {f1:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall   : {recall:.4f}\")\n",
    "# Binary Classification Evaluator for AUC\n",
    "binary_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"Price_Change\",\n",
    "    rawPredictionCol=\"rawPrediction\",  # required for AUC\n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "\n",
    "auc_mlp = binary_evaluator.evaluate(mlp_predictions)\n",
    "print(f\"  AUC (ROC) for Multi Layer Perceptron: {auc_mlp:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b9bc0-fef6-4521-800c-4bd1203133d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1525d0-5648-46d3-a35a-1b64a855b9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
